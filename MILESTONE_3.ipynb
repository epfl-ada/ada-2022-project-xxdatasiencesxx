{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a112c633-faf6-4243-8618-c8d0de5c1b1c",
   "metadata": {},
   "source": [
    "# The Outcasts of Hollywood \n",
    "### Ada CS-401 Project \n",
    "### Autumn 2022 - xxdatasiencesxx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a79e4ce",
   "metadata": {},
   "source": [
    "#### SUMMARY: \n",
    "1. NLP \n",
    "1. Genders and ethnicities of the actors\n",
    "    1. Movie revenue distribution in main character database versus cmu movies\n",
    "    1. Genre distribution in cmu database versus main character database\n",
    "    1. Are movies genres and gender of the lead role related?\n",
    "    1. Adding the ethnicity of actors (when available)\n",
    "1. Gender of the crew\n",
    "    1. Data preprocessing\n",
    "    1. Are the proportions of movies with women in the crew or created by men different ? \n",
    "    1. Does the proportion of movies with women in the crew change with time ?\n",
    "1. Revenue comparisons\n",
    "    1. In terms of the gender of the main actor\n",
    "    1. In terms of the gender of the crew \n",
    "    1. OLS to predict the revenue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0362fb5-a173-43b4-86bc-5fcf62bd23c1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 0 - Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "bc5dbdc4-6323-48db-874d-15076b4fce46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import gzip\n",
    "import glob, os\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import chart_studio\n",
    "import chart_studio.tools as tls\n",
    "import chart_studio.plotly as py\n",
    "\n",
    "path = '../MovieSummaries/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "6a71c685",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'MovieSummaries/ethnicity_query.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [118]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m directors_sex \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgit_all_directors_gender.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m mainchar_budget \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkaggle_movies.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m ethnicity_query \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMovieSummaries/ethnicity_query.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m;\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    665\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    666\u001b[0m     dialect,\n\u001b[1;32m    667\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    676\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    677\u001b[0m )\n\u001b[1;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    572\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    574\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 575\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/Anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    932\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 933\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1213\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1214\u001b[0m \u001b[38;5;66;03m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m \u001b[38;5;66;03m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[1;32m   1216\u001b[0m \u001b[38;5;66;03m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[0;32m-> 1217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[1;32m   1218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1226\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1227\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1228\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/Anaconda3/lib/python3.9/site-packages/pandas/io/common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    784\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    785\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    786\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    788\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    797\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    798\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'MovieSummaries/ethnicity_query.csv'"
     ]
    }
   ],
   "source": [
    "# Load various datasets\n",
    "movies_db = pd.read_pickle(path + 'movies_db.pickle')\n",
    "name_clusters = pd.read_pickle(path + 'name_clusters.pickle')\n",
    "crew_basic = pd.read_csv(path + \"imdb_crew.tsv\", sep=\"\\t\")\n",
    "name_basics = pd.read_csv(path + \"imdb_name_basics.tsv\", sep=\"\\t\")\n",
    "movie_basics = pd.read_csv(path + \"imdb_movie_basics.tsv\", sep=\"\\t\", low_memory=False)\n",
    "directors_sex = pd.read_csv(path + \"git_all_directors_gender.csv\", sep=\",\")\n",
    "mainchar_budget = pd.read_csv(path + \"kaggle_movies.csv\", sep=\",\")\n",
    "ethnicity_query = pd.read_csv('MovieSummaries/ethnicity_query.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d9ff92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this project, we will focus on american movies\n",
    "movies_usa = movies_db[movies_db['countries'].apply(lambda x: '\"/m/09c7w0\": \"United States of America\"' in x)]\n",
    "print(f\"Out of our database, we have {len(movies_usa)} american movies.\")\n",
    "print(f\"We ignore {len(movies_db)-len(movies_usa)} movies from the original dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23aaaf9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_usa.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a205c68",
   "metadata": {},
   "source": [
    "# 1 - NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33dc0694",
   "metadata": {},
   "source": [
    "# 2 - Gender and ethnicities of the actors \n",
    "\n",
    "The following analysis will try to give an answer to two questions. \n",
    "1. Are the genre of a movie and the ethnicity of the lead role correlated?\n",
    "2. Are the genre of a movie and the gender of the lead role correlated?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e234eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the main character to the movies_crew database\n",
    "# load dataset of movies with main character from 1980 onwards\n",
    "main_char = pd.read_csv(\"MovieSummaries/main_char.csv\", sep= \",\")\n",
    "main_char.drop_duplicates()\n",
    "print(f\"We are working with a dataset of {len(main_char)} movies for main characters.\")\n",
    "main_char.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72f39b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_movies_usa = len(movies_usa[movies_usa['release']> '1980-12-06'])\n",
    "len_main_char = len(main_char)\n",
    "print(f\"By using the main character's database, we lose {len_movies_usa - len_main_char} movies.\")\n",
    "print(f\"This is because not all movies in movies_crew are present in the main_char database.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea15ffb",
   "metadata": {},
   "source": [
    "## 2.1 - Movie revenue distribution in main character database versus cmu movies\n",
    "\n",
    "Let us investigate significant differences between the main character dataset we are using and the cmu movie database provided to us for the project.\n",
    "\n",
    "The role of the following analysis will be to see if our results can be biased based on the movie revenues in the datasets.\n",
    "\n",
    "For example, if most movies in the main character database have a higher average revenue, then we can say our analyis mostly applies to movies with high revenue and can be biased for movies of lower revenue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293be38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us see if the movies_usa database is similar to the main_char movie database by looking at the \n",
    "# distribution of their features\n",
    "# such as revenue, etc. \n",
    "# features they have in commun are 'genre', 'revenue', 'languages(doesn't make sense)'\n",
    "\n",
    "# plot histograms of the revenue of movies in both databases\n",
    "\n",
    "fig, axs = plt.subplots(1,2, figsize=(10,5), sharex=True, sharey=True)\n",
    "\n",
    "axs[0].hist(main_char['gross'], bins = 20)\n",
    "axs[0].set_title('Main Character Database Revenue distribution')\n",
    "axs[0].semilogy()\n",
    "\n",
    "axs[1].hist(movies_usa['revenue'], bins = 20)\n",
    "axs[1].set_title('CMU Database Revenue distribution for american movies')\n",
    "axs[1].semilogy()   \n",
    "    \n",
    "plt.tight_layout()\n",
    "print(\"The revenue distribution looks simmilar.\")\n",
    "print(\"However, the main character database does seem to have more movies with higher revenue.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcab9bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Let us check if the different between the revenues is significant.\")\n",
    "\n",
    "# let us first compute the mean\n",
    "print(f\"The mean revenue in the main character database is {main_char['gross'].mean()}.\")\n",
    "print(f\"The mean revenue for the movie metadata database for american movies is {movies_usa[movies_usa['release']> '1980-12-06']['revenue'].mean()}\")\n",
    "print(f\"On average, the revenue of movies in the main character database is {round(movies_usa['revenue'].mean()/main_char['gross'].mean(),4)*100}% higher than the revenue of cmu movies.\")                                                                                                                                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85641a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will use hypothesis testing to see if the revenue of movies in one dataset is bigger than the other\n",
    "# 'Ho = the distribution is the same' is the hypothesis\n",
    "\n",
    "print(stats.ttest_ind(main_char['gross'], movies_usa[movies_usa['release']> '1980-12-06']['revenue'], nan_policy='omit'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484fa166",
   "metadata": {},
   "source": [
    "#### Observations from movie revenue analysis\n",
    "The p-value is much smaller than 0.05, meaning we can safely reject the null hypothesis that the mean revenues for movies from the two databases are the same.\n",
    "The value of the test statistic is positive, hence, the mean revenue of movies in the main character dataset is larger.\n",
    "Therefore, analysis done in this study applies on american movies released after June 1980 with on average high revenue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217d860e",
   "metadata": {},
   "source": [
    "## 2.2 - Genre distribution in cmu database versus main character database\n",
    "\n",
    "Let us investigate more significant differences between the main character dataset we are using and the cmu movie database provided to us for the project. \n",
    "\n",
    "The role of the following analysis will be to see if our results can be biased based on the prevalence of certain movie genres in the dataset.\n",
    "\n",
    "For example, if most movies in the main character database are thrillers, then we can say our analyis mostly applies to thrillers and can be biased for movies of other genres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa12c7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now get us see if some movie genres are over or under represented in one database compared to the other\n",
    "# Let us store the genre distribution of the main character movie database in a dataframe\n",
    "\n",
    "# initialize data frame\n",
    "\n",
    "# create an array of all the genres \n",
    "genres = main_char['genre'].unique()\n",
    "\n",
    "# initialize data frame\n",
    "main_char_genres = pd.DataFrame(columns=['movie_number_main_char', 'movie_%_main_char'], \n",
    "                  index = [genres])\n",
    "\n",
    "# fill dataframe with the number and proportion \n",
    "for genre in range(len(genres)):\n",
    "    \n",
    "    main_char_genres.iat[genre,0] = main_char[main_char['genre']==genres[genre]]['genre'].count()\n",
    "    main_char_genres.iat[genre,1] = round(main_char_genres.iat[genre,0]/len(main_char)*100,2)\n",
    "    \n",
    "main_char_genres.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6abe744",
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = np.array(['Drama', 'Adventure', 'Action', 'Comedy', 'Horror', 'Biography',\n",
    "       'Crime', 'Fantasy', 'Family', 'Science Fiction', 'Animation', 'Romance',\n",
    "       'Music', 'Western', 'Thriller', 'History', 'Mystery', 'Sport',\n",
    "       'Musical'])\n",
    "\n",
    "movies_usa_genres = pd.DataFrame(columns=['movie_number_usa', 'movie_%_usa'], \n",
    "                  index = [genres])\n",
    "\n",
    "# fill dataframe with the number and proportion \n",
    "for genre in range(len(genres)):\n",
    "    \n",
    "    movies_usa_genres.iat[genre,0]=movies_usa[movies_usa['genres'].apply(lambda x: genres[genre] in x)]['genres'].count()\n",
    "    \n",
    "\n",
    "for genre in range(len(genres)):\n",
    "    movies_usa_genres.iat[genre,1]= round(movies_usa_genres.iat[genre,0]/sum(movies_usa_genres['movie_number_usa']) *100,2)\n",
    "\n",
    "#movies_usa_genres.sort_values(by = 'movie_number')    \n",
    "movies_usa_genres.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ab5e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#movies_usa_genres['genre'] = movies_usa_genres.index\n",
    "# creating the bar plot\n",
    "ax = sns.countplot(data=main_char, x=\"genre\")\n",
    "ax.set_xticklabels(labels=genres,rotation=90);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f295d602",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_usa_genres['genre']=movies_usa_genres.index\n",
    "ax = movies_usa_genres.plot.bar(x='genre', y='movie_number_usa', rot=90) \n",
    "print(\"The genre distribution of the two movies looks very different.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77a8fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us compare the proportions:\n",
    "genre_compare = pd.concat([movies_usa_genres[['movie_%_usa']] ,main_char_genres[['movie_%_main_char']] ], axis = 1)\n",
    "genre_compare['movie_%_main_char'][9] = 0.13\n",
    "genre_compare['difference'] = genre_compare['movie_%_usa']-genre_compare['movie_%_main_char']\n",
    "genre_compare = genre_compare.sort_values(by ='difference', ascending = 0)\n",
    "genre_compare.head(19)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcdfb89",
   "metadata": {},
   "source": [
    "#### Observations from genre distribution Analysis\n",
    "Our analysis dataset has a smaller proportion of drama, thriller, Romance, Family and Science fiction movies than the original dataset, as well has a much much bigger proportion of Action, Comedy, and Biography movies.\n",
    "\n",
    "Therefore, we can say that our analysis is mostly valid for Action, Comedy and Biography movies, but very innacurate for Thrillers, Romance and Family movies. This is a limitation of our study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4376c1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"We are supposed to have about {len(main_char)} movies until the end.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb07f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the main characters to the movies_usa dataset by merge \n",
    "main_char.drop(columns = ['runtime'],inplace = True)\n",
    "movies_usa_lead = pd.merge(movies_usa, main_char, how='inner', left_on='name', right_on='name')\n",
    "movies_usa_lead.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d969d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"There are {len(movies_usa[movies_usa['release']> '1980-12-06'])-len(main_char[main_char.index<6445])} movies lost when we use the main_char dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b24adef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Length after merge: {len(movies_usa_lead)}.\")\n",
    "print(f\"We lose {len(main_char[main_char.index<6445]) - len(movies_usa_lead)} movies of missing movies in either dataset or different spelling of the movie title.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d44c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load characters metadata dataset with all characters and their gender\n",
    "characters_db = pd.read_pickle('MovieSummaries/characters_db.pickle')\n",
    "characters_db.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c129c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "characters_db.drop(columns = ['char_name', 'release'], inplace = True)\n",
    "#characters_db.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f213cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_usa_gender = pd.merge(movies_usa_lead, characters_db, how = 'inner', right_on= ['wiki_movieID', 'act_name'], left_on = ['wiki_movieID', 'star'])\n",
    "movies_usa_gender.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a9ebe1",
   "metadata": {},
   "source": [
    "## 2.3 - Are movies genres and gender of the lead role related?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ec206b",
   "metadata": {},
   "source": [
    "### 2.3.1 - Naïve analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7396ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us first build a contingency table for analysis \n",
    "\n",
    "gender_contingency = pd.crosstab(movies_usa_gender['gender'], \n",
    "                            movies_usa_gender['genre'],\n",
    "                                margins = False)\n",
    "gender_contingency.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b1a7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us first visualize this contingency table\n",
    "\n",
    "X = movies_usa_gender['genre'].unique()\n",
    "Y_female = gender_contingency.loc['F',:]\n",
    "Y_male = gender_contingency.loc['M',:]\n",
    "X_axis = np.arange(len(X))\n",
    "\n",
    "plt.figure(figsize=(15,4))\n",
    "plt.bar(X_axis-0.2, Y_female, 0.4, label = 'Female', color = 'orchid')\n",
    "plt.bar(X_axis+0.2, Y_male, 0.4, label = 'Male', color = 'royalblue')\n",
    "\n",
    "plt.xticks(X_axis, X, rotation = 90)\n",
    "plt.xlabel(\"Genres\")\n",
    "plt.ylabel(\"Number of lead roles\")\n",
    "plt.title(\"Lead role gender by movie genre\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(\"It looks like male actors systemacically have a higher chance at the lead role, with the differences depending upon which movie genre we look at. For example, for action movies, men are far more likely to have the lead role than women, whereas in drama movies, this difference is less stark.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6c0f46",
   "metadata": {},
   "source": [
    "### 2.3.2 - Statistical analysis \n",
    "#### Note: \n",
    "For some movies genres (Sci-Fi, Family, Thriller, Fantasy, Mysterym, Romance and Western) we don't have enough data points to do a firm analysis, hence, we will drop them and focus our analysis for Drama, Action, Comedy, Crime, Biography, Adventure, Animation and Horror movies. This is a limitation of our study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daec4ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let us do more rebust tests with statistical methods\n",
    "# get us look at the correlation between the gender of the lead role and the genre of a movie\n",
    "\n",
    "gender_contingency = gender_contingency[['Drama','Action','Comedy','Crime','Biography','Adventure','Animation','Horror']]\n",
    "genres = gender_contingency.columns\n",
    "# we will use Cramer's V method to calculate the correlation coefficient between the categorical variables\n",
    "dataset = np.array(gender_contingency)\n",
    "\n",
    "X2 = stats.chi2_contingency(dataset, correction=False)[0]\n",
    "N = np.sum(dataset)\n",
    "minimum_dimension = min(dataset.shape)-1\n",
    "  \n",
    "# Calculate Cramer's V\n",
    "result = np.sqrt((X2/N) / minimum_dimension)\n",
    "print(f\"R = {result}\")\n",
    "print(\"The correlation coefficient R is high enough to investigate further.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1fa0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us use the chi-squared test \n",
    "\n",
    "dataset = np.array(gender_contingency)\n",
    "\n",
    "stat, p_value, dof, expected_freq = stats.chi2_contingency(dataset)\n",
    "print(f\"Test statistic = {stat}, p-value = {p_value}\")\n",
    "print(\"The p-value is much smaller than 0.05, so we can reject the null hypothesis that the gender of the lead actor isn't related genre of the movie. \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4bc717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let is try to compare the exèected frequencies and observed frequencies and visualise the difference\n",
    "# we will plot them side by side \n",
    "\n",
    "# creating a new contingency table out of expected frequencies given by the shi-squared test\n",
    "gender_contingency_x2 = pd.DataFrame(expected_freq, columns = genres, index = ['F','M'])\n",
    "\n",
    "# converting frequencies into percentages\n",
    "gender_contingency_x2 = gender_contingency_x2.apply(lambda x: x/sum(x))\n",
    "gender_contingency = gender_contingency.apply(lambda x: x/sum(x))\n",
    "\n",
    "# preparing X and Y values for bar plots\n",
    "X = genres\n",
    "Y_female = gender_contingency.loc['F',:]\n",
    "Y_male = gender_contingency.loc['M',:]\n",
    "X_axis = np.arange(len(X))\n",
    "\n",
    "Y_female_exp = gender_contingency_x2.loc['F',:]\n",
    "Y_male_exp = gender_contingency_x2.loc['M',:]\n",
    "\n",
    "contingency_diff = gender_contingency-gender_contingency_x2\n",
    "Y_female_diff = contingency_diff.loc['F',:]\n",
    "Y_male_diff = contingency_diff.loc['M',:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5b37ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let is visualise the difference between the expected values and the observed values \n",
    "# the expected values in a chi-squared test are the values we would expect if the null hypothesis were true\n",
    "# meaning the frequencies we could expect if the gender of the lead actor and movie genre were not correlated\n",
    "\n",
    "# plot \n",
    "fig, ax = plt.subplots(3,1, figsize=(15,10))\n",
    "\n",
    "ax[0].bar(X_axis-0.2, Y_female_exp, 0.4, label = 'Female', color = 'orchid')\n",
    "ax[0].bar(X_axis+0.2, Y_male_exp, 0.4, label = 'Male', color = 'royalblue')\n",
    "\n",
    "ax[1].bar(X_axis-0.2, Y_female, 0.4, label = 'Female', color = 'orchid')\n",
    "ax[1].bar(X_axis+0.2, Y_male, 0.4, label = 'Male', color = 'royalblue')\n",
    "\n",
    "ax[2].bar(X_axis-0.2, Y_female_diff, 0.4, label = 'Female', color = 'orchid')\n",
    "ax[2].bar(X_axis+0.2, Y_male_diff, 0.4, label = 'Male', color = 'royalblue')\n",
    "y = 0*X_axis\n",
    "ax[2].plot(X_axis,y,'-k')\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax[0].set_ylabel('Genres')\n",
    "ax[0].set_title('Expected Frequencies')\n",
    "ax[0].set_xticks(X_axis, genres)\n",
    "ax[0].legend()\n",
    "ax[1].set_ylabel('Genres')\n",
    "ax[1].set_title('Observed Frequencies')\n",
    "ax[1].set_xticks(X_axis, genres)\n",
    "ax[1].legend()\n",
    "ax[2].set_ylabel('Genres')\n",
    "ax[2].set_title('Difference between expected and observed frequencies')\n",
    "ax[2].set_xticks(X_axis, genres)\n",
    "ax[2].legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7cddae",
   "metadata": {},
   "source": [
    "####  Observations:\n",
    "Without any correlation between the gender of the lead role and movies genre, men are expected to lead ≃ 75% of movies of all genres and women are expected to lead ≃ 25% of movies across all genres(This is because men are generally occupy the main role in movies more often than women). However, the observed values differ from this prediciton. On average, women occupy 25% of the lead roles in movies and men occupy 75% of them.\n",
    "\n",
    "**Drama Films:** In Drama films, women occupy the lead role ≃ 35% of the time and men ≃ 65% of the time. Comparing with the expected values, this means american cinema is more likely to choose women as lead role in Drama movies than men than average.\n",
    "\n",
    "**Comedy Films:** In Comedy films, women occupy the lead role ≃ 30% of the time and men ≃ 70% of the time. Comaring with the expected frequencies, american cinema is more likely to choose women as lead role in Comedy movies than men than average.\n",
    "\n",
    "**Action Films:** In Action films, men occupy the lead role more than 90% of the time while women occupy it less than 10% of the time. Comparing this to the expected values, american cinema is more likely to choose men as their lead role in action movies than average.\n",
    "\n",
    "**Crime Films:** In Crime films, men occupy the lead role more than 80% of the time while women occupy it less than 20% of the time. Comparing is to the expected frequencies, american cinema is more likely to choose men as their lead role in crime movies on average.\n",
    "\n",
    "**Biography Films:** In Biography films, men occupy the lead role about 70% of the time while women occupy it about 30% of the time. Comparing this to the expected values, Biography films star women a bit more than average.\n",
    "\n",
    "**Adventure Films:** In Adventure films, men occupy the lead role more than 70% of the time while women occupy it less than 30% of the time. Comparing this to the expected values, Adventure films star women a bit more than average.\n",
    "\n",
    "**Horror Films:** Horror films seem to do the best in terms of gender distribution of main roles. Women occupy the lead role 44% of the tie while men occupy it 55% of the time. Comparing this to the expected values, Horror movies are much more likely to portray women than men compared to average.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61523f5f",
   "metadata": {},
   "source": [
    "## 2.4 - Adding the ethnicity of actors (when available)\n",
    "In this section, we will use the cum character database that has the freebaseID of actor's ethnicty, and match it with the ethnicities in our ethnicity query database that contains the ethnicity corresponding to every freebaseID code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1c6156",
   "metadata": {},
   "outputs": [],
   "source": [
    "## adding ethnicity of every main actor \n",
    "\n",
    "# load ethnicity query database containing corresponding ethnicity of every freebaseID code\n",
    "\n",
    "ethnicity_query = pd.read_csv(\"MovieSummaries/ethnicity_query.csv\",sep=\";\" )\n",
    "ethnicity_query.rename(columns = {'name': 'ethnicity_original'}, inplace = True)\n",
    "ethnicity_query.rename(columns = {'freebaseID': 'ethnicity_freebaseID'}, inplace = True)\n",
    "ethnicity_query.drop(columns = ['item'], inplace = True)\n",
    "ethnicity_query.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6498de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load characters metadata dataset with all characters and their eithnicity code \n",
    "characters_db = pd.read_pickle('MovieSummaries/characters_db.pickle')\n",
    "characters_db.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9821be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add correct ethnicity in characters_db instead of code with help of ethnicity_query table\n",
    "\n",
    "characters_db = pd.merge(characters_db, ethnicity_query, how='inner', left_on='ethnicity', right_on='ethnicity_freebaseID')\n",
    "characters_db.drop(columns = ['ethnicity_x'], inplace = True)\n",
    "characters_db.rename(columns = {'ethnicity_y': 'ethnicity'}, inplace = True)\n",
    "characters_db.drop(columns = ['height'], inplace = True)\n",
    "characters_db.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b2cd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "characters_db.drop(columns = ['char_name', 'release'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8ba9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(movies_usa_lead))\n",
    "movies_usa_ethnicity = pd.merge(movies_usa_lead, characters_db, how = 'inner', right_on= ['wiki_movieID', 'act_name'], left_on = ['wiki_movieID', 'star'])\n",
    "print(len(movies_usa_ethnicity))\n",
    "movies_usa_ethnicity.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80f2ef4",
   "metadata": {},
   "source": [
    "#### Observations \n",
    "We notice here that we go from a dataset of 6151 movies to a dataset of 1741 movies by merging characters_db and movies_usa_lead. This is because of the ethnicity column. Movies are un-able to merge and lost because of two reasons. Either the ethnicity of the actor was not available in the characters_db dataset. Or the freebaseID ethnicity code in characters_db  didn't correspond to any codes in our query table. We will however continue our analysis on ethnicity of lead roles in american movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abaa487f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build contingency table for movie genres and ethnicity of main actors \n",
    "\n",
    "ethnicity_contingency = pd.crosstab(movies_usa_ethnicity['genre'], \n",
    "                            movies_usa_ethnicity['ethnicity'],\n",
    "                                margins = False)\n",
    "ethnicity_contingency.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40dc3eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns with very small number of data points\n",
    "ethnicity_contingency.drop(index = ['Thriller','Romance', 'Sci-Fi','Mystery','Fantasy','Family'], inplace = True)\n",
    "\n",
    "# aggregate Asian ethnicity columns \n",
    "ethnicity_contingency['Asian'] = ethnicity_contingency['East Asian']+ ethnicity_contingency['Indo-Aryan']+ethnicity_contingency['South Asian']+ ethnicity_contingency['South-East Asian']+ ethnicity_contingency['West Asian']\n",
    "\n",
    "# drop useless Asian ethnicity columns\n",
    "ethnicity_contingency.drop(columns = ['East Asian','Indo-Aryan','South Asian','South-East Asian','West Asian'], inplace = True)\n",
    "\n",
    "# put native pacific islander ethnicit with 'others'\n",
    "ethnicity_contingency['Other'] = ethnicity_contingency['Other']+ethnicity_contingency['Native Pacific Islander']\n",
    "ethnicity_contingency.drop(columns = ['Native Pacific Islander'], inplace = True)\n",
    "\n",
    "# put multiracial Amercian ethnicity with 'other'\n",
    "ethnicity_contingency['Other'] = ethnicity_contingency['Other']+ethnicity_contingency['Multiracial American']\n",
    "ethnicity_contingency.drop(columns = ['Multiracial American'], inplace = True)\n",
    "\n",
    "ethnicity_contingency = ethnicity_contingency.transpose()\n",
    "\n",
    "ethnicity_contingency.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6e9980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us first visualize this contingency table\n",
    "\n",
    "ax = ethnicity_contingency.plot.bar(rot=90, figsize = (20,5))\n",
    "ax.semilogy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d4eff4",
   "metadata": {},
   "source": [
    "### 2.4.1 - Statistical analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df4dbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let us do more rebust tests with statistical methods\n",
    "# get us look at the correlation between the gender of the lead role and the genre of a movie\n",
    "\n",
    "genres = ethnicity_contingency.columns\n",
    "# we will use Cramer's V method to calculate the correlation coefficient between the categorical variables\n",
    "dataset_eth = np.array(ethnicity_contingency)\n",
    "\n",
    "X2_eth = stats.chi2_contingency(dataset_eth, correction=False)[0]\n",
    "N = np.sum(dataset_eth)\n",
    "minimum_dimension = min(dataset_eth.shape)-1\n",
    "  \n",
    "# Calculate Cramer's V\n",
    "result = np.sqrt((X2_eth/N) / minimum_dimension)\n",
    "print(f\"R = {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22cf61d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chi-squared test\n",
    "dataset_eth = np.array(ethnicity_contingency)\n",
    "\n",
    "stat_eth, p_value_eth, dof_eth, expected_freq_eth = stats.chi2_contingency(dataset_eth)\n",
    "print(f\"Test statistic = {stat_eth}, p-value = {p_value_eth}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347191b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(expected_freq_eth, index = ethnicity_contingency.index, columns = ethnicity_contingency.columns).apply(lambda x: x/sum(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b48ecd3",
   "metadata": {},
   "source": [
    "The p-value of the chi-square test is much smaller than 0.05, hence, we can reject the null hypothesis that there is no relationship between the ethnicity of the main actor and genre of the movie. Let us investigate further. We will compare the expected frequencies with the observed frequencies of the number of actors for the lead of a movie by genre per ethnicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be75a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting expected frequencies into percentages\n",
    "exp = pd.DataFrame(expected_freq_eth, index = ethnicity_contingency.index, columns = ethnicity_contingency.columns).apply(lambda x: x/sum(x))\n",
    "\n",
    "# plotting the expected frequencies\n",
    "ax1 = exp.plot.bar(rot=90, figsize = (20,5))\n",
    "ax1.semilogy()\n",
    "ax1.set_title('Expected Frequencies')\n",
    "\n",
    "# converting observed frequencies into percentages\n",
    "obs = pd.DataFrame(ethnicity_contingency).apply(lambda x: x/sum(x))\n",
    "\n",
    "# plotting the observed frequencies\n",
    "ax2= obs.plot.bar(rot=90, figsize = (20,5))\n",
    "ax2.semilogy()\n",
    "ax2.set_title('Observed Frequencies')\n",
    "\n",
    "# getting difference between observed and expected frequencies in percentage\n",
    "y = 0*X_axis\n",
    "diff_eth = obs - exp\n",
    "\n",
    "# plotting the difference\n",
    "ax3= diff_eth.plot.bar(rot=90, figsize=(20,6))\n",
    "ax3.plot(X_axis*2,y,'-k')\n",
    "ax3.set_title('Difference between observed and expected frequencies')\n",
    "ax3.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ceb6bb9",
   "metadata": {},
   "source": [
    "# 3 - Gender of the crew"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e437277-54d7-450c-95d7-54cf3ec900cd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3.1 - Data preprocessing\n",
    "First, we need to process the data to get a dataframe that also contains the crew information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78138bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge ImDB crew and movie info\n",
    "crew_title = pd.merge(crew_basic, movie_basics, on = 'tconst')\n",
    "crew_title.rename(columns = {'primaryTitle': 'name'}, inplace = True)\n",
    "\n",
    "# Duplicates in the crew_title dataset are deleted\n",
    "# Still difference with number of unique names -> group by name by aggregating to a list the other info\n",
    "crew_title = crew_title[['name', 'directors', 'writers']].drop_duplicates().groupby(\"name\").aggregate(lambda x: tuple(x))\n",
    "movies_crew = movies_usa.merge(crew_title, on = 'name', how = 'inner')\n",
    "movies_crew = movies_crew.dropna()\n",
    "\n",
    "# Add gender to name dataset - \n",
    "# Use of the ImdB dataset to get info on director and not just use of the directors_sex because it hase multiple \n",
    "# directors per movies and contains info on writers as well. Also, it is a more reliable source\n",
    "directors_sex.rename(columns = {'director': 'primaryName'}, inplace = True)\n",
    "name_genders = pd.merge(name_basics, directors_sex[['primaryName', 'gender']], on = 'primaryName')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a232bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_crew.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca3b775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print info possibly lost \n",
    "print(f'Total movies at beginning: {len(movies_db)}')\n",
    "print(f'Total american movies: {len(movies_usa)}')\n",
    "print(f'After merge with crew info: {len(movies_crew)}')\n",
    "print(f'\\nSamples lost to have info on crew/director: {len(movies_usa) - len(movies_crew)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b66e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the presence of at least one women or all women in crew to DataFrame\n",
    "women = name_genders[name_genders['gender']=='female']['nconst']\n",
    "movies_crew['dir_one_fem'] = movies_crew['directors'].progress_apply(\n",
    "    lambda x: any(const_women == const_dir\n",
    "                  for directors in x\n",
    "                  for const_dir in directors.split(',')\n",
    "                  for const_women in women\n",
    "                 )) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae70be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_crew['dir_all_fem'] = movies_crew['directors'].progress_apply(\n",
    "    lambda x: all(const_women == const_dir\n",
    "                  for directors in x\n",
    "                  for const_dir in directors.split(',')\n",
    "                  for const_women in women\n",
    "                 )) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611295f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_crew['wri_one_fem'] = movies_crew['writers'].progress_apply(\n",
    "    lambda x: any(const_women == const_wri\n",
    "                  for writers in x\n",
    "                  for const_wri in writers.split(',')\n",
    "                  for const_women in women\n",
    "                 )) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d351b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_crew['wri_all_fem'] = movies_crew['writers'].progress_apply(\n",
    "    lambda x: all(const_women == const_wri\n",
    "                  for writers in x\n",
    "                  for const_wri in writers.split(',')\n",
    "                  for const_women in women\n",
    "                 )) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbaa9bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_crew.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee23cbe4-71e0-496b-b2f3-c5cae006e56a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3.2 -  Does the proportion of movies with women in the crew change with time ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb2054d",
   "metadata": {},
   "source": [
    "### 3.2.1 - Yearly means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04907f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the year out of the date \n",
    "movies_crew['year'] = pd.to_datetime(movies_crew['release']).apply(lambda x: x.year)\n",
    "movies_crew = movies_crew.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e750cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build specific DataFrames\n",
    "# For this part, wa refers to at least one woman, w to all women, m to all men\n",
    "# In terms of the directors\n",
    "movies_dir_wa = movies_crew[movies_crew['dir_one_fem']==True]\n",
    "movies_dir_w = movies_crew[movies_crew['dir_all_fem']==True]\n",
    "movies_dir_m = movies_crew[movies_crew['dir_one_fem']==False]\n",
    "# In terms of the writers\n",
    "movies_wri_wa = movies_crew[movies_crew['wri_one_fem']==True]\n",
    "movies_wri_w = movies_crew[movies_crew['wri_all_fem']==True]\n",
    "movies_wri_m = movies_crew[movies_crew['wri_one_fem']==False]\n",
    "# In terms of whole crew \n",
    "movies_crew['crew_one_fem'] = movies_crew['wri_one_fem'].apply(lambda x: int(x)) + movies_crew['dir_one_fem'].apply(lambda x: int(x)) > 0\n",
    "movies_wa = pd.concat([ movies_crew[movies_crew['wri_one_fem']==True] , movies_crew[movies_crew['dir_one_fem']==True]])\n",
    "movies_w = movies_crew[movies_crew['wri_all_fem']==True][movies_crew['dir_all_fem']==True]\n",
    "movies_m = movies_crew[movies_crew['wri_one_fem']==False][movies_crew['dir_one_fem']==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895fe664",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tot = len(movies_crew)\n",
    "# Check proportions of women directors\n",
    "print('Number of movies directed by all women: ' + f\"{len(movies_dir_w)}\" + \" == \" + \"{:.2%}\".format(len(movies_dir_w) / tot) + \" of total movies in dataset\")\n",
    "print('Number of movies directed by at least one woman: ' + f\"{len(movies_dir_wa)}\" + \" == \" + \"{:.2%}\".format(len(movies_dir_wa) / tot) + \" of total movies in dataset\")\n",
    "print('Number of movies directed by all men: ' + f\"{len(movies_dir_m)}\" + \" == \" + \"{:.2%}\".format(len(movies_dir_m) / tot) +  \" of total movies in dataset\")\n",
    "\n",
    "# Check proportions of women writters\n",
    "print('\\nNumber of movies written by all women: ' + f\"{len(movies_wri_w)}\" + \" == \" + \"{:.2%}\".format(len(movies_wri_w) / tot) + \" of total movies in dataset\")\n",
    "print('Number of movies written by at least one woman: ' + f\"{len(movies_wri_wa)}\" + \" == \" + \"{:.2%}\".format(len(movies_wri_wa) / tot) + \" of total movies in dataset\")\n",
    "print('Number of movies written by all men: ' + f\"{len(movies_wri_m)}\" + \" == \" + \"{:.2%}\".format(len(movies_wri_m) / tot) + \" of total movies in dataset\")\n",
    "\n",
    "# Check proportions of women crew members\n",
    "print('\\nNumber of movies written and directed by women: ' + f\"{len(movies_w)}\" + \" == \" + \"{:.2%}\".format(len(movies_w) / tot) + \" of total movies in dataset\")\n",
    "print('Number of movies written and directed by at least one woman: ' + f\"{len(movies_wa)}\" + \" == \" + \"{:.2%}\".format(len(movies_wa) / tot) + \" of total movies in dataset\")\n",
    "print('Number of movies written and directed by all men: ' + f\"{len(movies_m)}\" + \" == \" + \"{:.2%}\".format(len(movies_m) / tot) + \" of total movies in dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb1479e",
   "metadata": {},
   "source": [
    "### 3.2.2 - Plot the yearly evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2adf0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# yearly releases of movies \n",
    "tot = movies_crew.groupby('year').aggregate('count')['wiki_movieID']\n",
    "# Yearly releases of movies directed by men/women \n",
    "plot_w_d = movies_crew.groupby('year').aggregate(sum)['dir_all_fem'] \n",
    "plot_wa_d = movies_crew.groupby('year').aggregate(sum)['dir_one_fem']  \n",
    "# Yearly releases of movies written by men/women \n",
    "plot_w_w = movies_crew.groupby('year').aggregate(sum)['wri_all_fem']\n",
    "plot_wa_w = movies_crew.groupby('year').aggregate(sum)['wri_one_fem']  \n",
    "# Yearly releases of movies containing at least one woman in the crew\n",
    "plot_wa = movies_crew.groupby('year').aggregate(sum)['crew_one_fem']  \n",
    "plot_m = tot - plot_wa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e2c0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=plot_wa_d.index, y=plot_wa_d/tot*100, name='At least one woman director',\n",
    "                         line=dict(color='#72B7B2', width=4)))\n",
    "\n",
    "fig.add_trace(go.Scatter(x=plot_wa_w.index, y=plot_wa_w/tot*100, name='At least one woman writer',\n",
    "                         line=dict(color='#9467BD', width=4, dash='dot')))\n",
    "\n",
    "\n",
    "fig.add_trace(go.Scatter(x=plot_wa.index, y=plot_wa/tot*100, name='At least one woman in the crew',\n",
    "                         line=dict(color='#E45756', width=4, dash='dash')))\n",
    "\n",
    "# Edit the layout\n",
    "fig.update_layout(title='Percentage of movies with women in the crew through the years',\n",
    "                   xaxis_title='Year',\n",
    "                   yaxis_title='Percentage of movies')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b13d2a",
   "metadata": {},
   "source": [
    "### 3.2.3 -  Statstical tests\n",
    "To look at the impact of the gender on the number of movies we will use the Mann Whitney U test. The Mann-Whitney U test is a nonparametric test of the null hypothesis that the distribution underlying sample x is the same as the distribution underlying sample y. It is often used as a test of difference in location between distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc7043e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the distribution of the number of movies created by men is different than the distribution of movies\n",
    "# that have at least one woman in the crew\n",
    "result = stats.mannwhitneyu(plot_wa, plot_m)\n",
    "print(result)\n",
    "print('The p-value is under 0.05 so there we can significantly reject the null hypothesis. \\nThe two distributions are statistically different.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3cecb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the proportion of women in the crew changes with time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cc3dde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ef1fde8f",
   "metadata": {},
   "source": [
    "# 4 - Revenue comparisons \n",
    "\n",
    "Finally, we will answer these questions: \n",
    "\n",
    "Is there a noticeable difference in revenue for movies that portray some particular genre? Is there a noticeable difference in revenue for movies created by women ?\n",
    "\n",
    "We will not look at the statistical difference for ethnicities as there are not enough minorities samples. However, the impact of main character being white or not will be measured in part 4.3. \n",
    "\n",
    "To look at the impact of the gender on the revenue we will use the Mann Whitney U test. The Mann-Whitney U test is a nonparametric test of the null hypothesis that the distribution underlying sample x is the same as the distribution underlying sample y. It is often used as a test of difference in location between distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e86857",
   "metadata": {},
   "source": [
    "## 4.1 - In terms of the gender of the main actor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2ac027",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08ec9f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b31898d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196f6ae3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9ee149",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "71ebab1b",
   "metadata": {},
   "source": [
    "## 4.2 - In terms of the gender of the crew"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8659e351",
   "metadata": {},
   "source": [
    "### 4.2.1 - Naïve approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c74676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot revenue distribution comparison between gender of the crew\n",
    "fig = px.histogram(movies_crew, x=\"revenue\", color=\"crew_one_fem\", log_y=True)\n",
    "\n",
    "# Overlay both histograms\n",
    "fig.update_layout(barmode='overlay')\n",
    "# Reduce opacity to see both histograms\n",
    "fig.update_traces(opacity=0.75)\n",
    "\n",
    "# Edit the layout\n",
    "fig.update_layout(title='Percentage of movies with women in the crew through the years',\n",
    "                   xaxis_title='Year',\n",
    "                   yaxis_title='Percentage of movies')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743cb2b6",
   "metadata": {},
   "source": [
    "### 4.2.2 - Matching revenue with budget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3702d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_budget = pd.merge(movies_crew, mainchar_budget[['name', 'budget']], on = 'name').dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e670fe91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Info lost \n",
    "print(f'Total movies at beginning: {len(movies_crew)}')\n",
    "print(f'After merge with budget info: {len(movies_budget)}')\n",
    "print(f'\\nSamples lost to have info on budget: {len(movies_crew) - len(movies_budget)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f01d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation between budget and revenue\n",
    "result = stats.pearsonr(movies_budget['revenue'], movies_budget['budget'])\n",
    "print(result)\n",
    "print('p-vaue is below 0.05. \\nThere is a significant positive correlation between the revenue and the budget. \\nMatching on the budget to study the revenue makes sense.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db46aa17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess movie_budget df\n",
    "movies_budget = movies_budget.dropna()\n",
    "movies_budget['dir_one_fem'] = movies_budget['dir_one_fem'].apply(lambda x: int(x))\n",
    "print(movies_budget.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfaf3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate in the two groups to be matched (at least one women, only men)\n",
    "wa = movies_budget[movies_budget['crew_one_fem'] == 1]\n",
    "m = movies_budget[movies_budget['crew_one_fem'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eab18cc-8d59-4aba-b31b-2629b656bd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through all the pairs of instances\n",
    "for m_id, m_row in m.iterrows():\n",
    "    k = -1\n",
    "    for wa_id, wa_row in wa.iterrows():\n",
    "        k = k+1 \n",
    "        if abs(wa_row['budget'] - m_row['budget']) < 0.1 * m_row['budget']:\n",
    "            # Add the matched pair to the matched dataframe \n",
    "            matched_df = matched_df.append(m_row) \n",
    "            matched_df = matched_df.append(wa_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c258058",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(matched_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4850b6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_df.head(2)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd858c1",
   "metadata": {},
   "source": [
    "### 4.2.3 - Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060bc4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot revenue distribution comparison between gender of the crew\n",
    "fig = px.histogram(matched_df, x=\"revenue\", color=\"crew_one_fem\", log_y=True)\n",
    "\n",
    "# Overlay both histograms\n",
    "fig.update_layout(barmode='overlay')\n",
    "# Reduce opacity to see both histograms\n",
    "fig.update_traces(opacity=0.75)\n",
    "\n",
    "# Edit the layout\n",
    "fig.update_layout(title='Percentage of movies with women in the crew through the years',\n",
    "                   xaxis_title='Year',\n",
    "                   yaxis_title='Percentage of movies')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04d55b0",
   "metadata": {},
   "source": [
    "### 4.2.4 - Statistical tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bda3bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation between gender of crew and revenue\n",
    "revenue_F = matched_df[matched_df['crew_one_fem']==1]['budget']\n",
    "revenue_M = matched_df[matched_df['crew_one_fem']==0]['budget']\n",
    "result = stats.mannwhitneyu(revenue_F, revenue_M)\n",
    "print('AFTER MATCHING')\n",
    "print(result)\n",
    "print('p-value smaller than 0.05 so we can reject the null hypthesis. \\nThe distribution of the revenue is different if the crew contains a woman or not.') \n",
    "\n",
    "# Results before matching\n",
    "revenue_F = movies_crew[movies_crew['crew_one_fem']==1]['budget']\n",
    "revenue_M = movies_crew[movies_crew['crew_one_fem']==0]['budget']\n",
    "result = stats.mannwhitneyu(revenue_F, revenue_M)\n",
    "print('\\nBEFORE MATCHING')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece7df7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation between gender of crew and revenue\n",
    "revenue_F = matched_df[matched_df['crew_one_fem']==1]['revenue']\n",
    "revenue_M = matched_df[matched_df['crew_one_fem']==0]['revenue']\n",
    "result = stats.mannwhitneyu(revenue_F, revenue_M)\n",
    "print('AFTER MATCHING')\n",
    "print(result)\n",
    "print('p-value smaller than 0.05 so we can reject the null hypthesis. \\nThe distribution of the revenue is different if the crew contains a woman or not.') \n",
    "\n",
    "# Results before matching\n",
    "revenue_F = movies_crew[movies_crew['crew_one_fem']==1]['revenue']\n",
    "revenue_M = movies_crew[movies_crew['crew_one_fem']==0]['revenue']\n",
    "result = stats.mannwhitneyu(revenue_F, revenue_M)\n",
    "print('\\nBEFORE MATCHING')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49483d1",
   "metadata": {},
   "source": [
    "## 4.3 - OLS to predict the revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec52e0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(matched_df.columns)\n",
    "print(mainchar_budget.columns)\n",
    "print(movies_usa_ethnicity.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0903080",
   "metadata": {},
   "outputs": [],
   "source": [
    "ols_df = pd.merge(mainchar_budget[['name', 'genre']], matched_df, on='name')\n",
    "ols_df = pd.merge(movies_usa_ethnicity[['name', 'ethnicity']], ols_df, on='name')\n",
    "\n",
    "genres = ols_df['genre'].unique()\n",
    "genres_dummies = pd.get_dummies(ols_df['genre'])\n",
    "\n",
    "ethinicity_dummies = pd.get_dummies(ols_df['ethnicity'])\n",
    "\n",
    "ols_df = pd.concat([ols_df, genres_dummies, ethinicity_dummies['White']], axis = 1)\n",
    "ols_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c63318",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ols_df['genre'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d1444716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>revenue</td>     <th>  R-squared:         </th> <td>   0.407</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.381</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   15.28</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 12 Dec 2022</td> <th>  Prob (F-statistic):</th> <td>7.95e-19</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>12:54:21</td>     <th>  Log-Likelihood:    </th> <td> -4252.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   210</td>      <th>  AIC:               </th> <td>   8525.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   200</td>      <th>  BIC:               </th> <td>   8559.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     9</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "            <td></td>              <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>            <td>-3.872e+09</td> <td> 1.26e+09</td> <td>   -3.083</td> <td> 0.002</td> <td>-6.35e+09</td> <td> -1.4e+09</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>crew_one_fem[T.True]</th> <td> 4.259e+07</td> <td> 2.27e+07</td> <td>    1.872</td> <td> 0.063</td> <td>-2.26e+06</td> <td> 8.75e+07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>budget</th>               <td>  8.58e+07</td> <td> 1.07e+07</td> <td>    7.985</td> <td> 0.000</td> <td> 6.46e+07</td> <td> 1.07e+08</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>year</th>                 <td> 1.974e+06</td> <td> 6.28e+05</td> <td>    3.144</td> <td> 0.002</td> <td> 7.36e+05</td> <td> 3.21e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Action</th>               <td>-2.999e+07</td> <td> 3.93e+07</td> <td>   -0.763</td> <td> 0.446</td> <td>-1.07e+08</td> <td> 4.75e+07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Adventure</th>            <td>-1.295e+08</td> <td>  5.7e+07</td> <td>   -2.273</td> <td> 0.024</td> <td>-2.42e+08</td> <td>-1.72e+07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Drama</th>                <td>-2.043e+07</td> <td> 4.43e+07</td> <td>   -0.461</td> <td> 0.645</td> <td>-1.08e+08</td> <td>  6.7e+07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Animation</th>            <td> 9.942e+07</td> <td>    5e+07</td> <td>    1.989</td> <td> 0.048</td> <td> 8.71e+05</td> <td> 1.98e+08</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Comedy</th>               <td>-3.741e+07</td> <td> 4.11e+07</td> <td>   -0.910</td> <td> 0.364</td> <td>-1.18e+08</td> <td> 4.37e+07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Horror</th>               <td>-6.885e+07</td> <td> 6.83e+07</td> <td>   -1.008</td> <td> 0.315</td> <td>-2.04e+08</td> <td> 6.58e+07</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>94.765</td> <th>  Durbin-Watson:     </th> <td>   1.273</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td> 499.768</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.689</td> <th>  Prob(JB):          </th> <td>3.00e-109</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 9.760</td> <th>  Cond. No.          </th> <td>2.35e+05</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 2.35e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                revenue   R-squared:                       0.407\n",
       "Model:                            OLS   Adj. R-squared:                  0.381\n",
       "Method:                 Least Squares   F-statistic:                     15.28\n",
       "Date:                Mon, 12 Dec 2022   Prob (F-statistic):           7.95e-19\n",
       "Time:                        12:54:21   Log-Likelihood:                -4252.6\n",
       "No. Observations:                 210   AIC:                             8525.\n",
       "Df Residuals:                     200   BIC:                             8559.\n",
       "Df Model:                           9                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "========================================================================================\n",
       "                           coef    std err          t      P>|t|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------\n",
       "Intercept            -3.872e+09   1.26e+09     -3.083      0.002   -6.35e+09    -1.4e+09\n",
       "crew_one_fem[T.True]  4.259e+07   2.27e+07      1.872      0.063   -2.26e+06    8.75e+07\n",
       "budget                 8.58e+07   1.07e+07      7.985      0.000    6.46e+07    1.07e+08\n",
       "year                  1.974e+06   6.28e+05      3.144      0.002    7.36e+05    3.21e+06\n",
       "Action               -2.999e+07   3.93e+07     -0.763      0.446   -1.07e+08    4.75e+07\n",
       "Adventure            -1.295e+08    5.7e+07     -2.273      0.024   -2.42e+08   -1.72e+07\n",
       "Drama                -2.043e+07   4.43e+07     -0.461      0.645   -1.08e+08     6.7e+07\n",
       "Animation             9.942e+07      5e+07      1.989      0.048    8.71e+05    1.98e+08\n",
       "Comedy               -3.741e+07   4.11e+07     -0.910      0.364   -1.18e+08    4.37e+07\n",
       "Horror               -6.885e+07   6.83e+07     -1.008      0.315   -2.04e+08    6.58e+07\n",
       "==============================================================================\n",
       "Omnibus:                       94.765   Durbin-Watson:                   1.273\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              499.768\n",
       "Skew:                           1.689   Prob(JB):                    3.00e-109\n",
       "Kurtosis:                       9.760   Cond. No.                     2.35e+05\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 2.35e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform an ordinary least squares linear regression\n",
    "test_df = ols_df.copy()\n",
    "test_df['revenue'] = pd.to_numeric(test_df['revenue'])\n",
    "test_df['budget'] = pd.to_numeric(test_df['budget'])\n",
    "test_df['year'] = pd.to_numeric(test_df['year'])\n",
    "test_df['Action'] = pd.to_numeric(test_df['Action'])\n",
    "\n",
    "results = smf.ols('revenue ~ budget + crew_one_fem + year + White + Action + Adventure + Drama + Animation + Comedy + Horror', data=test_df).fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b2f2ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
